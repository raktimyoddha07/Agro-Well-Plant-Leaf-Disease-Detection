{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b64b5-53fa-4bdc-ac4e-97ff696255de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = r\"C:\\Users\\rakti\\Downloads\\a\\Final-project\\Datasets\\npld_kmeans\\train\"\n",
    "val_dir = r\"C:\\Users\\rakti\\Downloads\\a\\Final-project\\Datasets\\npld_kmeans\\test\"\n",
    "test_dir = r\"C:\\Users\\rakti\\Downloads\\a\\Final-project\\Datasets\\npld_kmeans\\val\"\n",
    "\n",
    "# Load datasets\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63362c9-8be9-41c9-a8cd-1ee63e8387fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = models.vgg16(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "train_acc_vgg16, val_acc_vgg16 = [], []\n",
    "train_loss_vgg16, val_loss_vgg16 = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc_vgg16.append(correct / total)\n",
    "    train_loss_vgg16.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct, val_total, val_loss_epoch = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss_epoch += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc_vgg16.append(val_correct / val_total)\n",
    "    val_loss_vgg16.append(val_loss_epoch / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc_vgg16[-1]:.4f} | Val Acc: {val_acc_vgg16[-1]:.4f} | Train Loss: {train_loss_vgg16[-1]:.4f} | Val Loss: {val_loss_vgg16[-1]:.4f}\")\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_vgg16, label='Train Accuracy')\n",
    "plt.plot(val_acc_vgg16, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy per Epoch (VGG16)')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_vgg16, label='Train Loss')\n",
    "plt.plot(val_loss_vgg16, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Epoch (VGG16)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Evaluation\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Metrics\n",
    "acc_vgg16 = accuracy_score(all_labels, all_preds)\n",
    "prec_vgg16 = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec_vgg16 = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1_vgg16 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\nTest Accuracy: {acc_vgg16:.4f}\")\n",
    "print(f\"Precision: {prec_vgg16:.4f}\")\n",
    "print(f\"Recall: {rec_vgg16:.4f}\")\n",
    "print(f\"F1 Score: {f1_vgg16:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "class_names = train_data.classes\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - VGG16')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3ef59-88cd-4ace-83e3-561c83dca300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 Model\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model_vgg19 = models.vgg19(pretrained=True)\n",
    "for param in model_vgg19.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "model_vgg19.classifier[6] = nn.Linear(model_vgg19.classifier[6].in_features, num_classes)\n",
    "model_vgg19 = model_vgg19.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_vgg19.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "train_acc_vgg19, val_acc_vgg19, train_loss_vgg19, val_loss_vgg19 = [], [], [], []\n",
    "\n",
    "# Training loop for 50 epochs\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model_vgg19.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_vgg19(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_acc_vgg19.append(correct / total)\n",
    "    train_loss_vgg19.append(running_loss / len(train_loader))\n",
    "\n",
    "    model_vgg19.eval()\n",
    "    val_running_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_vgg19(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc_vgg19.append(val_correct / val_total)\n",
    "    val_loss_vgg19.append(val_running_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc_vgg19[-1]:.4f} |  Val Acc: {val_acc_vgg19[-1]:.4f} | Train Loss: {train_loss_vgg19[-1]:.4f} | Val Loss: {val_loss_vgg19[-1]:.4f}\")\n",
    "\n",
    "# Accuracy & Loss Graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_vgg19, label=\"Train Acc\")\n",
    "plt.plot(val_acc_vgg19, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"VGG19 Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_vgg19, label=\"Train Loss\")\n",
    "plt.plot(val_loss_vgg19, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"VGG19 Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Metrics\n",
    "model_vgg19.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_vgg19(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc_vgg19 = accuracy_score(all_labels, all_preds)\n",
    "prec_vgg19 = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec_vgg19 = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1_vgg19 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\nVGG19 Test Accuracy: {acc_vgg19:.4f}\")\n",
    "print(f\"Precision: {prec_vgg19:.4f}\")\n",
    "print(f\"Recall: {rec_vgg19:.4f}\")\n",
    "print(f\"F1 Score: {f1_vgg19:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=train_data.classes,\n",
    "            yticklabels=train_data.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('VGG19 Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bcd6e-1b51-433b-9573-7f427188a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet121 Model\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model_dn121 = models.densenet121(pretrained=True)\n",
    "for param in model_dn121.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "model_dn121.classifier = nn.Linear(model_dn121.classifier.in_features, num_classes)\n",
    "model_dn121 = model_dn121.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_dn121.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "train_acc_dn121, val_acc_dn121, train_loss_dn121, val_loss_dn121 = [], [], [], []\n",
    "\n",
    "# Training loop for 50 epochs\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model_dn121.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_dn121(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_acc_dn121.append(correct / total)\n",
    "    train_loss_dn121.append(running_loss / len(train_loader))\n",
    "\n",
    "    model_dn121.eval()\n",
    "    val_running_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_dn121(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc_dn121.append(val_correct / val_total)\n",
    "    val_loss_dn121.append(val_running_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc_dn121[-1]:.4f} |  Val Acc: {val_acc_dn121[-1]:.4f} | Train Loss: {train_loss_dn121[-1]:.4f} | Val Loss: {val_loss_dn121[-1]:.4f}\")\n",
    "\n",
    "# Accuracy & Loss Graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_dn121, label=\"Train Acc\")\n",
    "plt.plot(val_acc_dn121, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"DenseNet121 Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_dn121, label=\"Train Loss\")\n",
    "plt.plot(val_loss_dn121, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"DenseNet121 Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Metrics\n",
    "model_dn121.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_dn121(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc_dn121 = accuracy_score(all_labels, all_preds)\n",
    "prec_dn121 = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec_dn121 = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1_dn121 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\nDenseNet121 Test Accuracy: {acc_dn121:.4f}\")\n",
    "print(f\"Precision: {prec_dn121:.4f}\")\n",
    "print(f\"Recall: {rec_dn121:.4f}\")\n",
    "print(f\"F1 Score: {f1_dn121:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=train_data.classes,\n",
    "            yticklabels=train_data.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('DenseNet121 Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2fd41-e7a8-4064-9ab9-85aa3abd1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet169 Model\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model_dn169 = models.densenet169(pretrained=True)\n",
    "for param in model_dn169.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_dn169.classifier = nn.Linear(model_dn169.classifier.in_features, num_classes)\n",
    "model_dn169 = model_dn169.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_dn169.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "train_acc_dn169, val_acc_dn169, train_loss_dn169, val_loss_dn169 = [], [], [], []\n",
    "\n",
    "# Training loop for 50 epochs\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model_dn169.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_dn169(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_acc_dn169.append(correct / total)\n",
    "    train_loss_dn169.append(running_loss / len(train_loader))\n",
    "\n",
    "    model_dn169.eval()\n",
    "    val_running_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_dn169(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc_dn169.append(val_correct / val_total)\n",
    "    val_loss_dn169.append(val_running_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc_dn169[-1]:.4f} |  Val Acc: {val_acc_dn169[-1]:.4f} | Train Loss: {train_loss_dn169[-1]:.4f} | Val Loss: {val_loss_dn169[-1]:.4f}\")\n",
    "\n",
    "# Accuracy & Loss Graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_dn169, label=\"Train Acc\")\n",
    "plt.plot(val_acc_dn169, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"DenseNet169 Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_dn169, label=\"Train Loss\")\n",
    "plt.plot(val_loss_dn169, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"DenseNet169 Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Metrics\n",
    "model_dn169.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_dn169(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc_dn169 = accuracy_score(all_labels, all_preds)\n",
    "prec_dn169 = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec_dn169 = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1_dn169 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\nDenseNet169 Test Accuracy: {acc_dn169:.4f}\")\n",
    "print(f\"Precision: {prec_dn169:.4f}\")\n",
    "print(f\"Recall: {rec_dn169:.4f}\")\n",
    "print(f\"F1 Score: {f1_dn169:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=train_data.classes,\n",
    "            yticklabels=train_data.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('DenseNet169 Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131b5db-b26a-4ebf-94ef-c1d4ce20ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet201 Model\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model_dn201 = models.densenet201(pretrained=True)\n",
    "for param in model_dn201.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_dn201.classifier = nn.Linear(model_dn201.classifier.in_features, num_classes)\n",
    "model_dn201 = model_dn201.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_dn201.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "train_acc_dn201, val_acc_dn201 = [], []\n",
    "train_loss_dn201, val_loss_dn201 = [], []\n",
    "\n",
    "# Training loop for 50 epochs\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model_dn201.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_dn201(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_acc_dn201.append(correct / total)\n",
    "    train_loss_dn201.append(running_loss / len(train_loader))\n",
    "\n",
    "    model_dn201.eval()\n",
    "    val_running_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_dn201(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc_dn201.append(val_correct / val_total)\n",
    "    val_loss_dn201.append(val_running_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc_dn201[-1]:.4f} |  Val Acc: {val_acc_dn201[-1]:.4f} | Train Loss: {train_loss_dn201[-1]:.4f} | Val Loss: {val_loss_dn201[-1]:.4f}\")\n",
    "\n",
    "# Accuracy & Loss Graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_dn201, label=\"Train Acc\")\n",
    "plt.plot(val_acc_dn201, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"DenseNet201 Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_dn201, label=\"Train Loss\")\n",
    "plt.plot(val_loss_dn201, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"DenseNet201 Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Metrics\n",
    "model_dn201.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_dn201(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc_dn201 = accuracy_score(all_labels, all_preds)\n",
    "prec_dn201 = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec_dn201 = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1_dn201 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\nDenseNet201 Test Accuracy: {acc_dn201:.4f}\")\n",
    "print(f\"Precision: {prec_dn201:.4f}\")\n",
    "print(f\"Recall: {rec_dn201:.4f}\")\n",
    "print(f\"F1 Score: {f1_dn201:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=train_data.classes,\n",
    "            yticklabels=train_data.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('DenseNet201 Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a45bf-261a-419e-8648-ea3f1fa59070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet V2S Model\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "\n",
    "model_eff_s = efficientnet_v2_s(pretrained=True)\n",
    "for param in model_eff_s.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_eff_s.classifier[1] = nn.Linear(model_eff_s.classifier[1].in_features, num_classes)\n",
    "model_eff_s = model_eff_s.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_eff_s.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "train_acc_eff_s, val_acc_eff_s = [], []\n",
    "train_loss_eff_s, val_loss_eff_s = [], []\n",
    "\n",
    "# Training loop for 50 epochs\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model_eff_s.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_eff_s(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_acc_eff_s.append(correct / total)\n",
    "    train_loss_eff_s.append(running_loss / len(train_loader))\n",
    "\n",
    "    model_eff_s.eval()\n",
    "    val_running_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_eff_s(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc_eff_s.append(val_correct / val_total)\n",
    "    val_loss_eff_s.append(val_running_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc_eff_s[-1]:.4f} |  Val Acc: {val_acc_eff_s[-1]:.4f} | Train Loss: {train_loss_eff_s[-1]:.4f} | Val Loss: {val_loss_eff_s[-1]:.4f}\")\n",
    "\n",
    "# Accuracy & Loss Graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_eff_s, label=\"Train Acc\")\n",
    "plt.plot(val_acc_eff_s, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"EfficientNet V2S Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_eff_s, label=\"Train Loss\")\n",
    "plt.plot(val_loss_eff_s, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"EfficientNet V2S Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Metrics\n",
    "model_eff_s.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_eff_s(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc_eff_s = accuracy_score(all_labels, all_preds)\n",
    "prec_eff_s = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec_eff_s = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1_eff_s = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\nEfficientNet V2S Test Accuracy: {acc_eff_s:.4f}\")\n",
    "print(f\"Precision: {prec_eff_s:.4f}\")\n",
    "print(f\"Recall: {rec_eff_s:.4f}\")\n",
    "print(f\"F1 Score: {f1_eff_s:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=train_data.classes,\n",
    "            yticklabels=train_data.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('EfficientNet V2S Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82166a-691e-4836-a24b-cd70bd69303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet V2M\n",
    "from torchvision.models import efficientnet_v2_m\n",
    "\n",
    "model_eff_m = efficientnet_v2_m(pretrained=True)\n",
    "for param in model_eff_m.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_eff_m.classifier[1] = nn.Linear(model_eff_m.classifier[1].in_features, num_classes)\n",
    "model_eff_m = model_eff_m.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_eff_m.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "train_acc_eff_m, val_acc_eff_m = [], []\n",
    "train_loss_eff_m, val_loss_eff_m = [], []\n",
    "\n",
    "for epoch in range(50):  # Set number of epochs to 50\n",
    "    model_eff_m.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_eff_m(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_acc_eff_m.append(correct / total)\n",
    "    train_loss_eff_m.append(running_loss / len(train_loader))\n",
    "\n",
    "    model_eff_m.eval()\n",
    "    val_running_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_eff_m(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc_eff_m.append(val_correct / val_total)\n",
    "    val_loss_eff_m.append(val_running_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc_eff_m[-1]:.4f} | Val Acc: {val_acc_eff_m[-1]:.4f} | Train Loss: {train_loss_eff_m[-1]:.4f} | Val Loss: {val_loss_eff_m[-1]:.4f}\")\n",
    "\n",
    "# Accuracy & Loss Graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_eff_m, label=\"Train Acc\")\n",
    "plt.plot(val_acc_eff_m, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"EfficientNet V2M Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_eff_m, label=\"Train Loss\")\n",
    "plt.plot(val_loss_eff_m, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"EfficientNet V2M Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Metrics\n",
    "model_eff_m.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_eff_m(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc_eff_m = accuracy_score(all_labels, all_preds)\n",
    "prec_eff_m = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec_eff_m = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1_eff_m = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\nEfficientNet V2M Test Accuracy: {acc_eff_m:.4f}\")\n",
    "print(f\"Precision: {prec_eff_m:.4f}\")\n",
    "print(f\"Recall: {rec_eff_m:.4f}\")\n",
    "print(f\"F1 Score: {f1_eff_m:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=train_data.classes,\n",
    "            yticklabels=train_data.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('EfficientNet V2M Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c9f176-85d6-47cf-b867-907963506ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2\n",
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "model_mob = mobilenet_v2(pretrained=True)\n",
    "for param in model_mob.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_mob.classifier[1] = nn.Linear(model_mob.classifier[1].in_features, num_classes)\n",
    "model_mob = model_mob.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_mob.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "train_acc_mob, val_acc_mob = [], []\n",
    "train_loss_mob, val_loss_mob = [], []\n",
    "\n",
    "for epoch in range(50):  # Fixed to 50 epochs\n",
    "    model_mob.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_mob(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_acc_mob.append(correct / total)\n",
    "    train_loss_mob.append(running_loss / len(train_loader))\n",
    "\n",
    "    model_mob.eval()\n",
    "    val_running_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_mob(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc_mob.append(val_correct / val_total)\n",
    "    val_loss_mob.append(val_running_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc_mob[-1]:.4f} | Val Acc: {val_acc_mob[-1]:.4f} | Train Loss: {train_loss_mob[-1]:.4f} | Val Loss: {val_loss_mob[-1]:.4f}\")\n",
    "\n",
    "# Accuracy & Loss Graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_mob, label=\"Train Acc\")\n",
    "plt.plot(val_acc_mob, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MobileNetV2 Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_mob, label=\"Train Loss\")\n",
    "plt.plot(val_loss_mob, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"MobileNetV2 Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Metrics\n",
    "model_mob.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_mob(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc_mob = accuracy_score(all_labels, all_preds)\n",
    "prec_mob = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec_mob = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1_mob = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\nMobileNetV2 Test Accuracy: {acc_mob:.4f}\")\n",
    "print(f\"Precision: {prec_mob:.4f}\")\n",
    "print(f\"Recall: {rec_mob:.4f}\")\n",
    "print(f\"F1 Score: {f1_mob:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=train_data.classes,\n",
    "            yticklabels=train_data.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('MobileNetV2 Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbb14e-cc54-4fea-9fbf-915ef8441b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Names (excluding InceptionV3 and GoogLeNet)\n",
    "model_names = [\n",
    "    'VGG16', 'VGG19', 'DenseNet121', 'DenseNet169', 'DenseNet201',\n",
    "    'EffNetV2-S', 'EffNetV2-M', 'MobileNetV2'\n",
    "]\n",
    "\n",
    "# Training & Validation Accuracy (excluding InceptionV3 and GoogLeNet)\n",
    "all_train_acc = [\n",
    "    train_acc_vgg16, train_acc_vgg19, train_acc_dn121, train_acc_dn169, train_acc_dn201,\n",
    "    train_acc_eff_s, train_acc_eff_m, train_acc_mob\n",
    "]\n",
    "\n",
    "all_val_acc = [\n",
    "    val_acc_vgg16, val_acc_vgg19, val_acc_dn121, val_acc_dn169, val_acc_dn201,\n",
    "    val_acc_eff_s, val_acc_eff_m, val_acc_mob\n",
    "]\n",
    "\n",
    "# Training & Validation Loss (excluding InceptionV3 and GoogLeNet)\n",
    "all_train_loss = [\n",
    "    train_loss_vgg16, train_loss_vgg19, train_loss_dn121, train_loss_dn169, train_loss_dn201,\n",
    "    train_loss_eff_s, train_loss_eff_m, train_loss_mob\n",
    "]\n",
    "\n",
    "all_val_loss = [\n",
    "    val_loss_vgg16, val_loss_vgg19, val_loss_dn121, val_loss_dn169, val_loss_dn201,\n",
    "    val_loss_eff_s, val_loss_eff_m, val_loss_mob\n",
    "]\n",
    "\n",
    "# Accuracy Comparison Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "for acc, name in zip(all_train_acc, model_names):\n",
    "    plt.plot(acc, label=f'{name}')\n",
    "plt.title(\"Training Accuracy Comparison\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for acc, name in zip(all_val_acc, model_names):\n",
    "    plt.plot(acc, label=f'{name}')\n",
    "plt.title(\"Validation Accuracy Comparison\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Loss Comparison Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "for loss, name in zip(all_train_loss, model_names):\n",
    "    plt.plot(loss, label=f'{name}')\n",
    "plt.title(\"Training Loss Comparison\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for loss, name in zip(all_val_loss, model_names):\n",
    "    plt.plot(loss, label=f'{name}')\n",
    "plt.title(\"Validation Loss Comparison\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d414a-ed16-4c86-94b2-c8c2f319ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model Names\n",
    "model_names = [\n",
    "    'VGG16', 'VGG19', 'DenseNet121', 'DenseNet169', 'DenseNet201',\n",
    "    'EffNetV2-S', 'EffNetV2-M', 'MobileNetV2'\n",
    "]\n",
    "\n",
    "# Replace these with your actual metric values\n",
    "summary_data = {\n",
    "    'Model': model_names,\n",
    "    'Accuracy': [\n",
    "        acc_vgg16, acc_vgg19, acc_dn121, acc_dn169, acc_dn201,\n",
    "        acc_eff_s, acc_eff_m, acc_mob\n",
    "    ],\n",
    "    'Precision': [\n",
    "        prec_vgg16, prec_vgg19, prec_dn121, prec_dn169, prec_dn201,\n",
    "        prec_eff_s, prec_eff_m, prec_mob\n",
    "    ],\n",
    "    'Recall': [\n",
    "        rec_vgg16, rec_vgg19, rec_dn121, rec_dn169, rec_dn201,\n",
    "        rec_eff_s, rec_eff_m, rec_mob\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_vgg16, f1_vgg19, f1_dn121, f1_dn169, f1_dn201,\n",
    "        f1_eff_s, f1_eff_m, f1_mob\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Format Accuracy to percentage (2 decimal places)\n",
    "summary_df['Accuracy'] = (summary_df['Accuracy'] * 100).round(2)\n",
    "\n",
    "# Round other metrics to 4 decimal places\n",
    "for metric in ['Precision', 'Recall', 'F1-Score']:\n",
    "    summary_df[metric] = summary_df[metric].round(4)\n",
    "\n",
    "# Display Table with Times New Roman and Column Spacing\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "html_table = summary_df.to_html(index=False)\n",
    "styled_html = f\"\"\"\n",
    "<style>\n",
    "    table {{\n",
    "        font-family: 'Times New Roman';\n",
    "        font-size: 14px;\n",
    "        border-collapse: separate;\n",
    "        border-spacing: 30px 5px;\n",
    "    }}\n",
    "    th, td {{\n",
    "        padding: 8px 20px;\n",
    "        text-align: center;\n",
    "    }}\n",
    "</style>\n",
    "{html_table}\n",
    "\"\"\"\n",
    "display(HTML(styled_html))\n",
    "\n",
    "# Set global font for plots\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# Bar Plot for Each Metric\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    sns.barplot(x='Model', y=metric, data=summary_df, palette='viridis')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'{metric} Comparison', fontsize=14)\n",
    "    plt.ylabel(f'{metric} (%)' if metric == 'Accuracy' else metric)\n",
    "    plt.ylim(0, 100 if metric == 'Accuracy' else 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271db607-643e-481c-af71-b84658a6e1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
